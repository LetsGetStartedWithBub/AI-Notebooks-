{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/Logos/organization_logo/organization_logo.png\" width = 400> </a>\n",
    "\n",
    "<h1 align=center><font size = 5>Pre-Trained Models</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, you will learn how to leverage pre-trained models to build image classifiers instead of building a model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3> \n",
    "    \n",
    "1. <a href=\"#item31\">Import Libraries and Packages</a>\n",
    "2. <a href=\"#item32\">Download Data</a>  \n",
    "3. <a href=\"#item33\">Define Global Constants</a>  \n",
    "4. <a href=\"#item34\">Construct ImageDataGenerator Instances</a>  \n",
    "5. <a href=\"#item35\">Compile and Fit Model</a>\n",
    "\n",
    "</font>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item31'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Import Libraries and Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's start the lab by importing the libraries that we will be using in this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "First, we will import the ImageDataGenerator module since we will be leveraging it to train our model in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/be/679ce5254a8c8d07470efb4a4c00345fae91f766e64f1c2aece8796d7218/tensorflow-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n",
      "\u001b[K     |████████████████████████████████| 516.2MB 35kB/s  eta 0:00:011                             | 4.8MB 5.4MB/s eta 0:01:36     |█                               | 15.4MB 31.5MB/s eta 0:00:16               | 16.9MB 31.5MB/s eta 0:00:16     |██▌                             | 39.6MB 37.7MB/s eta 0:00:13     |███▌                            | 56.1MB 5.4MB/s eta 0:01:25     |███▌                            | 56.8MB 5.4MB/s eta 0:01:25     |████▊                           | 75.9MB 6.9MB/s eta 0:01:05MB/s eta 0:01:00     |███████                         | 112.8MB 5.5MB/s eta 0:01:14     |███████▌                        | 120.8MB 2.7MB/s eta 0:02:28     |████████▍                       | 135.5MB 5.5MB/s eta 0:01:10     |████████▊                       | 140.6MB 7.0MB/s eta 0:00:54     |█████████▏                      | 148.3MB 7.0MB/s eta 0:00:53     |██████████                      | 162.4MB 7.0MB/s eta 0:00:51    | 204.8MB 9.6MB/s eta 0:00:33     |████████████▊                   | 205.2MB 9.6MB/s eta 0:00:33████▌                | 249.5MB 5.1MB/s eta 0:00:53     |███████████████▋                | 251.5MB 2.9MB/s eta 0:01:32     |████████████████▏               | 260.3MB 2.9MB/s eta 0:01:29     |████████████████▎               | 261.9MB 2.9MB/s eta 0:01:28     |████████████████▋               | 268.2MB 7.7MB/s eta 0:00:33     |████████████████▉               | 271.8MB 7.7MB/s eta 0:00:32     |████████████████▉               | 272.3MB 7.7MB/s eta 0:00:32     |█████████████████▎              | 279.6MB 6.7MB/s eta 0:00:36     |█████████████████▊              | 285.2MB 6.7MB/s eta 0:00:35     |█████████████████▊              | 286.1MB 6.7MB/s eta 0:00:35     |██████████████████▏             | 293.2MB 5.1MB/s eta 0:00:44     |███████████████████▌            | 314.1MB 7.0MB/s eta 0:00:30     |███████████████████▊            | 318.5MB 5.5MB/s eta 0:00:36     | 332.1MB 5.5MB/s eta 0:00:34�██████████          | 355.0MB 6.0MB/s eta 0:00:27�██████████          | 356.1MB 6.0MB/s eta 0:00:27��█████████████████████▋         | 364.9MB 6.0MB/s eta 0:00:26     |████████████████████████        | 386.5MB 7.0MB/s eta 0:00:19     |████████████████████████▋       | 397.7MB 6.9MB/s eta 0:00:18��█████████████████▏      | 406.2MB 6.7MB/s eta 0:00:17     |██████████████████████████      | 421.2MB 7.0MB/s eta 0:00:14     |████████████████████████████▎   | 456.2MB 7.0MB/s eta 0:00:09��████████████████████▍  | 474.1MB 7.1MB/s eta 0:00:06��████████████████████▉  | 481.5MB 5.5MB/s eta 0:00:07��█████████████████████  | 485.7MB 5.5MB/s eta 0:00:06    |██████████████████████████████▎ | 488.8MB 5.5MB/s eta 0:00:05     |███████████████████████████████ | 500.3MB 43.3MB/s eta 0:00:01     |███████████████████████████████▌| 507.7MB 7.0MB/s eta 0:00:02     |███████████████████████████████▋| 509.2MB 7.0MB/s eta 0:00:01     |███████████████████████████████▊| 510.9MB 7.0MB/s eta 0:00:01     |███████████████████████████████▊| 511.6MB 7.0MB/s eta 0:00:012.5MB 7.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/a5/e6c07b08b934831ccb8c98ee335e66b7761c5754ee3cabfe4c11d0b1af28/opt_einsum-3.2.1-py3-none-any.whl (63kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 6.4MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from tensorflow) (1.18.5)\n",
      "Collecting keras-preprocessing>=1.1.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 3.5MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.3.0,>=2.2.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n",
      "\u001b[K     |████████████████████████████████| 460kB 37.4MB/s eta 0:00:01��             | 266kB 37.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.8 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 19.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from tensorflow) (3.12.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting astunparse==1.6.3 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl\n",
      "Collecting wrapt>=1.11.1 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/82/f7/e43cefbe88c5fd371f4cf0cf5eb3feccd07515af9fd6cf7dbf1d1793a797/wrapt-1.12.1.tar.gz\n",
      "Collecting h5py<2.11.0,>=2.10.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 31.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from tensorflow) (1.23.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from tensorflow) (0.34.2)\n",
      "Collecting tensorboard<2.3.0,>=2.2.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 36.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorflow) (47.1.1.post20200529)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard<2.3.0,>=2.2.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/57/d706964a7e4056f3f2244e16705388c11631fbb53d3e2d2a2d0fbc24d470/google_auth-1.18.0-py2.py3-none-any.whl (90kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 25.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.3.0,>=2.2.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/85/5c5ac0a8c5efdfab916e9c6bc18963f6a6996a8a1e19ec4ad8c9ac9c623c/tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779kB)\n",
      "\u001b[K     |████████████████████████████████| 788kB 38.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.3.0,>=2.2.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.1)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.4.5.2)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/5c/f3aa86b6d5482f3051b433c7616668a9b96fbe49a622210e2c9781938a5c/cachetools-4.1.1-py3-none-any.whl\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3\" (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/df/c3587a667d6b308fadc90b99e8bc8774788d033efcc70f4ecaae7fad144b/rsa-4.6-py3-none-any.whl (47kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 17.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 7.0MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: wrapt\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/b1/c2/ed/d62208260edbd3fa7156545c00ef966f45f2063d0a84f8208a\n",
      "Successfully built wrapt\n",
      "\u001b[31mERROR: tensorboard 2.2.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.23.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: opt-einsum, keras-preprocessing, tensorflow-estimator, google-pasta, astunparse, wrapt, h5py, cachetools, rsa, google-auth, tensorboard-plugin-wit, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Found existing installation: h5py 2.8.0\n",
      "    Uninstalling h5py-2.8.0:\n",
      "      Successfully uninstalled h5py-2.8.0\n",
      "  Found existing installation: tensorboard 1.8.0\n",
      "    Uninstalling tensorboard-1.8.0:\n",
      "      Successfully uninstalled tensorboard-1.8.0\n",
      "  Found existing installation: tensorflow 1.8.0\n",
      "    Uninstalling tensorflow-1.8.0:\n",
      "      Successfully uninstalled tensorflow-1.8.0\n",
      "Successfully installed astunparse-1.6.3 cachetools-4.1.1 google-auth-1.18.0 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 h5py-2.10.0 keras-preprocessing-1.1.2 oauthlib-3.1.0 opt-einsum-3.2.1 requests-oauthlib-1.3.0 rsa-4.6 tensorboard-2.2.2 tensorboard-plugin-wit-1.7.0 tensorflow-2.2.0 tensorflow-estimator-2.2.0 wrapt-1.12.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/44/e1/dc0757b20b56c980b5553c1b5c4c32d378c7055ab7bfa92006801ad359ab/Keras-2.4.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "  Found existing installation: Keras 2.1.6\n",
      "    Uninstalling Keras-2.1.6:\n",
      "      Successfully uninstalled Keras-2.1.6\n",
      "Successfully installed keras-2.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, we will be using the Keras library to build an image classifier, so let's download the Keras library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we will be leveraging the ResNet50 model to build our classifier, so let's download it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.3\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item32'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "For your convenience, I have placed the data on a server which you can retrieve easily using the **wget** command. So let's run the following line of code to get the data. Given the large size of the image dataset, it might take some time depending on your internet speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-05 20:11:12--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip\n",
      "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
      "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 261482368 (249M) [application/zip]\n",
      "Saving to: ‘concrete_data_week3.zip.2’\n",
      "\n",
      "2                    58%[==========>         ] 145.89M  22.2MB/s    eta 6s     ^C\n"
     ]
    }
   ],
   "source": [
    "## get the data\n",
    "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now if you check the left directory pane, you should see the zipped file *concrete_data_week3.zip* appear. So, let's go ahead and unzip the file to access the images. Given the large number of images in the dataset, this might take a couple of minutes, so please be patient, and wait until the code finishes running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  concrete_data_week3.zip\n",
      "replace concrete_data_week3/valid/positive/16679_1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!unzip concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the folder *concrete_data_week3* appear in the left pane. If you open this folder by double-clicking on it, you will find that it contains two folders: *train* and *valid*. And if you explore these folders, you will find that each contains two subfolders: *positive* and *negative*. These are the same folders that we saw in the labs in the previous modules of this course, where *negative* is the negative class and it represents the concrete images with no cracks and *positive* is the positive class and it represents the concrete images with cracks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Important Note**: There are thousands and thousands of images in each folder, so please don't attempt to double click on the *negative* and *positive* folders. This may consume all of your memory and you may end up with a **50*** error. So please **DO NOT DO IT**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item33'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Define Global Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Here, we will define constants that we will be using throughout the rest of the lab. \n",
    "\n",
    "1. We are obviously dealing with two classes, so *num_classes* is 2. \n",
    "2. The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
    "3. We will training and validating the model using batches of 100 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "image_resize = 224\n",
    "\n",
    "batch_size_training = 100\n",
    "batch_size_validation = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item34'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Construct ImageDataGenerator Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to *preprocess_input* which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will use the *flow_from_directory* method to get the training images as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11454 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/train',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Your Turn**: Use the *flow_from_directory* method to get the validation images and assign the result to **validation_generator**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## Type your answer here\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Double-click __here__ for the solution.\n",
    "<!-- The correct answer is:\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')\n",
    "-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item35'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Build, Compile and Fit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this section, we will start building our model. We will use the Sequential model class from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model = tensorflow.keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will add the ResNet50 pre-trained model to out model. However, note that we don't want to include the top layer or the output layer of the pre-trained model. We actually want to define our own output layer and train it so that it is optimized for our image dataset. In order to leave out the output layer of the pre-trained model, we will use the argument *include_top* and set it to **False**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 4d473c1dd8becc155b73f8504c6f6626 so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model.add(ResNet50(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Then, we will define our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the model's layers using the *layers* attribute of our model object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.training.Model at 0x7feee0a8cda0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7feee09d9400>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can see that our model is composed of two sets of layers. The first set is the layers pertaining to ResNet50 and the second set is a single layer, which is our Dense layer that we defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the ResNet50 layers by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7feee1606240>,\n",
       " <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x7fef17809860>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee1606ba8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee1606cf8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee15bb9b0>,\n",
       " <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x7feee1593ba8>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7feee1521a90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee1626748>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee15552b0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee1555a90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee155b400>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee15016a0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee1501e80>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee15216a0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee1506898>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee1626470>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee14aeb70>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7feee14b12e8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee14b1cc0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee14d9eb8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee145f4a8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee145fd30>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee146d6a0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee1492940>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee1497b38>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee1497320>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee143ee10>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7feee1445588>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee1445f60>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee13f3400>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee13f3748>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee13f3f28>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee13fb940>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee141cc18>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee13a5dd8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee13a5588>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee13d40b8>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7feee13d45f8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee13da240>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee1388198>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee132da58>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee1335be0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee13353c8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee135bf28>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee12e2f60>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee13816a0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee1305d68>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee13819e8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee130f358>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7feee130f898>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee13164e0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee12bb940>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee12bbcc0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee12c1e80>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee12c1630>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee126f160>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee126f9e8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee1278320>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee129d5f8>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7feee129db38>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee12246d8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee124ebe0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee124efd0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee12547f0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee125b128>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee1201400>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee1201c88>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee12085f8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee11ae898>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7feee11b4a90>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee11b4a20>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee11dab38>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee1161208>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee1161a90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee116b400>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee11906a0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee1190e80>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee1194898>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee113eb70>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7feee11442e8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee1144cc0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee10ef9e8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee111e550>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee111ed30>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee10a56a0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee10c9940>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee10d2b38>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee10e8eb8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee10d2320>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee10ef4a8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee1076e10>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7feee107e588>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee107ef60>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee102c400>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee102c748>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee102cf28>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee1034940>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee1058c18>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0fe0dd8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0fe0588>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee100d0b8>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7feee100d5f8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee1017240>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0fbb6a0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0fbb9e8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0fc2be0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0fc23c8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0f6bf28>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0f70f60>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0f97d68>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0f1f358>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7feee0f1f898>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0f264e0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0f4d940>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0f4dcc0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0f52e80>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0f52630>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0f00160>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0f009e8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0f07320>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0eae5f8>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7feee0eaeb38>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0eb36d8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0edabe0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0edafd0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0d2f7f0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0d37128>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0d5f400>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0d5fc88>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0d655f8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0d0b898>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7feee0d13a90>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0d13a20>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0cb8b38>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0cbe208>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0cbea90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0cc8400>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0cec6a0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0cece80>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0c73898>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0c9ab70>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7feee0ca02e8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0ca0cc0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0c4f9e8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0bfe550>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0bfed30>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0c036a0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0c2a940>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0bb0b38>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0c47eb8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0bb02e8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0c4f4a8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fef1f99a978>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fef1f9834a8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fef1f96a780>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fef1f91e2e8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fef1f91f160>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0bcfb00>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0b74470>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0b9c748>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0b9cf28>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0b9f940>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0b45c88>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7feee0b4c400>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0b4cdd8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0afd278>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0afd630>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0afdeb8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0b047f0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0b2bba8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0ab0cf8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7feee0ab04a8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7feee0adf048>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7feee0adf588>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7feee0ae71d0>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x7feee0a8c6a0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since the ResNet50 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now using the *summary* attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next we compile our model using the **adam** optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "steps_per_epoch_training = len(train_generator)/ batch_size_training\n",
    "steps_per_epoch_validation = len(validation_generator)/ batch_size_validation\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-172e67583a70>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/2\n",
      "2/1 [====================================================] - 151s 76s/step - loss: 3.3496 - accuracy: 1.0000 - val_loss: 1.5756 - val_accuracy: 0.5400\n",
      "Epoch 2/2\n",
      "2/1 [====================================================] - 151s 75s/step - loss: 3.4084 - accuracy: 1.0000 - val_loss: 1.5558 - val_accuracy: 0.5250\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now that the model is trained, you are ready to start using it to classify images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since training can take a long time when building deep learning models, it is always a good idea to save your model once the training is complete if you believe you will be using the model again later. You will be using this model in the next module, so go ahead and save your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.save('classifier_resnet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the model file *classifier_resnet_model.h5* apprear in the left directory pane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by Alex Aklson. I hope you found this lab interesting and educational."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "This notebook is part of a course on **Coursera** called *AI Capstone Project with Deep Learning*. If you accessed this notebook outside the course, you can take this course online by clicking [here](https://cocl.us/DL0321EN_Coursera_Week3_LAB1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "Copyright &copy; 2020 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
